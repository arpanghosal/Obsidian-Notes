
Here I will dump physics stuffs. [[EFT]]

-   "Leading order" refers to the highest-order term in a perturbative expansion of a given quantity. In the context of Feynman diagrams, the leading order diagram is the one that involves the fewest number of loops. Loops represent quantum corrections to the classical interaction, and therefore diagrams with fewer loops are considered to be more accurate approximations of the actual physics.
    
-   "Tree level" diagrams are Feynman diagrams that contain no loops. They represent the classical, or tree-level, interaction between particles. The term "tree" comes from the fact that the diagram looks like a branching tree with particles as the branches.
    
-   "Born level" is another term used to describe tree-level diagrams, but specifically for particle scattering processes. In particular, the Born approximation is the leading term in a series expansion of the scattering amplitude, which is the probability of two particles scattering off each other. The Born level diagram, therefore, represents the lowest-order approximation of the scattering process.

In quantum field theory calculations, the perturbative expansion is usually carried out in powers of a small parameter, typically the coupling constant of the theory. The leading order (LO) term represents the contribution from the lowest power of this small parameter, while the next-to-leading order (NLO) term represents the contribution from the next power.

The LO term provides a good approximation to the physical process being studied, but it is not always accurate enough for precision measurements. In order to improve the accuracy of the calculation, one needs to include higher-order corrections, which correspond to diagrams with more loops and higher powers of the coupling constant.

The convergence of the perturbative expansion depends on the value of the coupling constant and the energy scale of the process being studied. At low energies, the coupling constant is typically small, and the perturbative expansion converges well. However, at higher energies, the coupling constant becomes larger, and the higher-order corrections become more important.

To account for these higher-order corrections, one can calculate the NLO contribution to the process being studied. The NLO term includes contributions from both LO and NLO diagrams, and it can significantly improve the accuracy of the calculation. However, the NLO term is typically more difficult to calculate than the LO term, as it involves more complicated diagrams and integrals.

Bias :
There are several types of bias that can occur in an experiment:

1.  Selection bias: This occurs when the sample chosen for the experiment is not representative of the population being studied. This can happen if the sample is chosen non-randomly or if certain groups are excluded from the study.
    
2.  Measurement bias: This occurs when the instruments or procedures used to make the measurements are inaccurate or imprecise, leading to a consistent over- or underestimation of the true value.
    
3.  Observer bias: This occurs when the researchers or observers involved in the experiment have preconceived ideas or expectations that influence the interpretation of the results.
    
4.  Confounding bias: This occurs when there is a variable that affects both the independent variable being studied and the outcome of interest, leading to a distorted or incorrect relationship between them.
    
5.  Reporting bias: This occurs when the results of the study are selectively reported, either by the researchers or by the media, in a way that distorts the true findings.
    

To minimize bias in an experiment, it is important to carefully design the study and control for potential sources of bias. This can involve using random sampling methods, blinding the observers or participants to the conditions of the study, using standardized and calibrated instruments, and reporting all results, regardless of whether they support the initial hypothesis or not.


**--- CP violating couplings ---**
CP-violating anomalous couplings refer to interactions between particles that violate both the symmetries of charge conjugation (C) and parity (P) conservation, and involve deviations from the expected behavior of particles predicted by the Standard Model of particle physics.

In the Standard Model, particles and their interactions are described by quantum field theory, and the theory predicts the strengths of various interactions between particles, including their coupling strengths. The couplings between particles can be represented by coupling constants, which are typically assumed to be constants that do not vary with energy or other parameters.

However, in some extensions of the Standard Model, such as in theories that include extra dimensions or new particles, anomalous couplings can arise. These anomalous couplings can result in deviations from the expected behavior of particles and interactions, and can lead to CP violation, where the laws of physics appear to behave differently for particles and their antiparticles.

Anomalous couplings can be studied experimentally by colliding particles at high energies and observing the resulting interactions. By carefully measuring the properties of the final state particles, such as their energies, momenta, and spin, physicists can infer the presence and strength of anomalous couplings. These measurements can help test the predictions of the Standard Model and search for evidence of new physics beyond it.

![[Pasted image 20230401220511.png]]

SUSY can solve mass hierarchy problem.
![[Pasted image 20230401220831.png]]



GIM mechanism  and Interference :

Interference occurs when two or more Feynman diagrams contribute to the same final state of a particle interaction. The probability amplitude for the overall process is obtained by summing the probability amplitudes of each individual Feynman diagram.

Interference can be constructive or destructive, depending on the relative phases of the probability amplitudes. Constructive interference occurs when the probability amplitudes have the same phase and reinforce each other, leading to an enhanced overall amplitude. Destructive interference, on the other hand, occurs when the probability amplitudes have opposite phases and tend to cancel each other out, resulting in a reduced overall amplitude.

In the context of the GIM mechanism, interference refers to the interference between different quark mixing pathways or Feynman diagrams involving the charm quark. These pathways represent different possibilities for the flavor-changing transition to occur. The interference arises because the charm quark can propagate through multiple pathways, contributing to the overall amplitude.

By considering the interference effects between the different pathways, we can observe cancellations or enhancements in the overall probability amplitude for the flavor-changing process. In the case of the GIM mechanism, the destructive interference between specific mixing pathways involving the charm quark leads to a suppression of Flavor Changing Neutral Current (FCNC) processes. The interference effects depend on the masses and couplings of the particles involved in the processes.

The GIM mechanism introduces the charm quark as an additional quark to cancel out unwanted FCNC effects. The charm quark's mass is indeed lighter than the W boson mass, but that is not the primary reason for its inclusion in the mechanism.

The interference between different quark mixing pathways, involving both the charm quark and the W boson exchange, is what leads to the suppression of FCNC processes. The interference effects depend on the masses and couplings of the particles involved, as well as the relative phases of the probability amplitudes associated with the different pathways.

The charm quark plays a crucial role in the GIM mechanism because its presence introduces additional pathways that interfere with the direct FCNC transitions mediated by the W boson. Through interference, these pathways contribute in a way that cancels out the FCNC effects, leading to the suppression of FCNC processes.

![[Pasted image 20230620135716.png]]

Buffer !

So FCNC is rare because :
1. GIM Mechanism: The Glashow-Iliopoulos-Maiani (GIM) mechanism, as we discussed earlier, plays a crucial role in suppressing FCNC processes. The interference effects between different quark mixing pathways, mediated by the GIM mechanism, lead to a cancellation or significant reduction of FCNC amplitudes.
    
2. Small Mixing Angles: The CKM matrix, which governs quark flavor mixing, contains small mixing angles. These angles represent the relative strengths of flavor-changing transitions. The small values of these mixing angles contribute to the suppression of FCNC processes, making them relatively rare compared to other interactions.
    
3. Loop Suppression: FCNC processes typically involve loop diagrams, which involve virtual particles running in loops. Loop processes are generally less likely to occur compared to tree-level processes due to the additional suppression factor associated with loop diagrams.
    
4. Weak Interaction Strength: The weak interaction itself is relatively weak compared to electromagnetic and strong interactions. This inherent weakness of the weak interaction contributes to the rarity of FCNC processes.



<mark style="background: #FFF3A3A6;">**While off-shell particles, which are virtual particles that can temporarily violate the mass-energy relation, can appear in intermediate states of Feynman diagrams, they still obey energy-momentum conservation laws when summed over all possible intermediate states.**
</mark>


## How are they all related after all?
1. Flavor Changing Neutral Current (FCNC): FCNC refers to processes in particle physics where a quark changes its flavor (type) without changing its electric charge. FCNC processes are highly suppressed in the Standard Model due to the Glashow-Iliopoulos-Maiani (GIM) mechanism.
    
2. Charged Lepton Flavor Violation (CLFV): CLFV refers to processes in which charged leptons (such as electrons or muons) change their flavor, violating the conservation of lepton flavor. CLFV is not allowed in the Standard Model but can occur in some theories beyond it.
    
3. GIM Mechanism: The GIM mechanism is a theoretical framework developed by Glashow, Iliopoulos, and Maiani. It introduces additional quark mixing pathways involving the charm quark to cancel out unwanted FCNC effects. The GIM mechanism achieves this through interference effects between different quark mixing pathways.
    
4. Charm Quark: The charm quark is the third lightest quark in the Standard Model, denoted as c. It plays a crucial role in the GIM mechanism by introducing additional quark mixing pathways that interfere with FCNC transitions. The presence of the charm quark helps suppress FCNC processes and ensures agreement with experimental observations.
    
5. Mass Suppression: Mass suppression refers to the reduction or suppression of FCNC processes due to interference effects between different quark mixing pathways. In the GIM mechanism, destructive interference between specific pathways involving the charm quark cancels out or reduces the contributions of FCNC processes, leading to their suppression.
    

These topics are interconnected, as the GIM mechanism, charm quark, and interference effects are all relevant to understanding and suppressing FCNC processes in particle physics. Additionally, CLFV processes, which involve violations of lepton flavor conservation, provide valuable insights into physics beyond the Standard Model.


[[Detector ]]

## Cross sections
In the context of physics, particularly in particle physics experiments, the terms "absolute cross section" and "normalized cross section" refer to different ways of quantifying and presenting experimental measurements.

1. Absolute Cross Section: The absolute cross section represents the likelihood of a specific process or interaction occurring when particles (such as protons or electrons) collide with each other. It is measured in units of area, typically in barns (1 barn = 10^-28 square meters).
    
    Absolute cross section measurements provide the actual probability or rate of a particular interaction occurring, regardless of the experimental conditions or the intensity of the particle beams. These measurements are essential for understanding the underlying physics processes and for comparison with theoretical predictions.
    
2. Normalized Cross Section: The normalized cross section is obtained by dividing the measured cross section by a reference value. The reference value is typically chosen based on certain conditions or assumptions, such as a specific energy range, detector acceptance, or a well-understood process.
    
    Normalized cross section measurements are useful for comparing data across different experiments, colliders, or energy regimes. They help to remove the effects of experimental setup differences and can provide insights into the underlying physical phenomena without being dependent on absolute values.


## why study prompt?
Prompt photons and prompt muons are two examples of such objects:

1. Prompt Photons: A prompt photon refers to a photon that is produced directly from the primary interaction vertex in a particle collision. It is not the result of the decay of other particles. Prompt photons can arise from various processes, such as quark-gluon interactions, annihilation processes, or the decay of other prompt particles. They are often used as a probe to study specific interactions or to search for new phenomena in high-energy collisions.
    
2. Prompt Muons: Similarly, a prompt muon is a muon that is produced directly from the primary interaction vertex. Muons are heavy leptons, and prompt muons can be produced in processes like Drell-Yan production, where a quark and an antiquark annihilate to produce a virtual photon or Z boson, which subsequently decays into a muon-antimuon pair. Prompt muons are crucial in precision measurements, such as the determination of the W boson mass or the search for rare processes.
---

## Development of PDFs for partons

Parton distribution functions (PDFs) are developed through a combination of theoretical calculations, experimental measurements, and statistical analysis. The construction of PDFs involves a multi-step process that incorporates various data sets and theoretical frameworks. Let's explore the general steps and touch upon the specific cases of NNPDF and CT10/CTEQ PDF sets.

1. Theoretical Framework: PDFs are typically calculated within the framework of Quantum Chromodynamics (QCD), the theory of the strong nuclear force. Perturbative QCD calculations provide the foundation for understanding the dynamics of partons and their interactions.
    
2. Initial Parametrization: An initial parametrization for the PDFs is chosen based on theoretical expectations and insights from previous studies. These parametrizations include functional forms with several free parameters that will be determined through fitting to experimental data.
    
3. Fitting to Data: Experimental data from a wide range of scattering experiments are used to constrain the free parameters of the PDF parametrization. These data sets include deep inelastic scattering, Drell-Yan processes, jet production, and other high-energy scattering processes. The goal is to find the best set of parameters that reproduce the experimental measurements.
    
4. Statistical Analysis: Statistical techniques, such as the method of least squares or maximum likelihood estimation, are employed to determine the best-fit values of the PDF parameters and to estimate the uncertainties associated with them.
    

Now, let's discuss the specific cases of NNPDF and CT10/CTEQ PDF sets:

NNPDF (part of the NNPDF Collaboration): The NNPDF approach uses a neural network methodology to determine the PDFs. Neural networks are trained on a large set of experimental data to directly extract the PDFs without assuming a specific functional form. The neural network framework provides flexibility in capturing complex PDF shapes and allows for a systematic estimation of uncertainties.

CT10/CTEQ (part of the CT Collaboration): The CT10/CTEQ PDF sets are obtained through global fits to experimental data. These fits involve a wide range of data sets and incorporate theoretical calculations within the framework of QCD. The CT10/CTEQ collaborations employ a specific parametrization form and perform iterative fitting procedures to determine the best-fit PDFs and uncertainties.

In both cases, NNPDF and CT10/CTEQ, the construction of PDF sets involves the combination of theoretical calculations, fitting procedures, and statistical analysis. These PDF sets are continuously updated as new data become available, allowing for improved precision and understanding of the proton's internal structure.

https://en.wikipedia.org/wiki/Parton_(particle_physics)#Parton_distribution_functions
https://en.wikipedia.org/wiki/DGLAP_evolution_equations

---
